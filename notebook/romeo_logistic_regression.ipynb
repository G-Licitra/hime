{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "therapeutic-survival",
   "metadata": {},
   "source": [
    "# Exploring the functionality within the `romeo.LogisticRegression` class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "changing-secretariat",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.datasets import make_classification\n",
    "from sklearn.metrics import log_loss, roc_curve, roc_auc_score, confusion_matrix\n",
    "import session_info\n",
    "\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "authentic-location",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_wd = os.getcwd()\n",
    "os.chdir(current_wd.split(\"/notebook\")[0])\n",
    "from romeo.logistic_model import LogisticRegression\n",
    "os.chdir(current_wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "civilian-cylinder",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fail to get yarn configuration. dyld: Library not loaded: /usr/local/opt/icu4c/lib/libicui18n.67.dylib\n",
      "  Referenced from: /usr/local/bin/node\n",
      "  Reason: image not found\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<details>\n",
       "<summary>Click to view session information</summary>\n",
       "<pre>\n",
       "-----\n",
       "matplotlib          3.3.4\n",
       "numpy               1.20.3\n",
       "pandas              1.1.5\n",
       "romeo               0.0.1\n",
       "seaborn             0.11.1\n",
       "session_info        1.0.0\n",
       "sklearn             0.23.2\n",
       "-----\n",
       "</pre>\n",
       "<details>\n",
       "<summary>Click to view modules imported as dependencies</summary>\n",
       "<pre>\n",
       "PIL                 8.3.1\n",
       "anyio               NA\n",
       "appnope             0.1.2\n",
       "attr                21.2.0\n",
       "babel               2.9.1\n",
       "backcall            0.2.0\n",
       "beta_ufunc          NA\n",
       "binom_ufunc         NA\n",
       "brotli              NA\n",
       "casadi              3.5.5\n",
       "certifi             2020.06.20\n",
       "cffi                1.14.6\n",
       "chardet             4.0.0\n",
       "charset_normalizer  2.0.0\n",
       "cycler              0.10.0\n",
       "cython_runtime      NA\n",
       "dateutil            2.8.2\n",
       "decorator           5.0.9\n",
       "defusedxml          0.7.1\n",
       "idna                3.1\n",
       "ipykernel           6.0.3\n",
       "ipython_genutils    0.2.0\n",
       "jedi                0.18.0\n",
       "jinja2              3.0.1\n",
       "joblib              1.0.1\n",
       "json5               NA\n",
       "jsonschema          3.2.0\n",
       "jupyter_server      1.10.1\n",
       "jupyterlab_server   2.6.1\n",
       "kiwisolver          1.3.1\n",
       "markupsafe          2.0.1\n",
       "matplotlib_inline   NA\n",
       "mpl_toolkits        NA\n",
       "nbclassic           NA\n",
       "nbformat            5.1.3\n",
       "nbinom_ufunc        NA\n",
       "packaging           21.0\n",
       "parso               0.8.2\n",
       "pexpect             4.8.0\n",
       "pickleshare         0.7.5\n",
       "pkg_resources       NA\n",
       "prometheus_client   NA\n",
       "prompt_toolkit      3.0.19\n",
       "ptyprocess          0.7.0\n",
       "pvectorc            NA\n",
       "pygments            2.9.0\n",
       "pyparsing           2.4.7\n",
       "pyrsistent          NA\n",
       "pytz                2021.1\n",
       "requests            2.26.0\n",
       "scipy               1.7.0\n",
       "send2trash          NA\n",
       "six                 1.16.0\n",
       "sniffio             1.2.0\n",
       "socks               1.7.1\n",
       "statsmodels         0.12.2\n",
       "storemagic          NA\n",
       "swig_runtime_data4  NA\n",
       "terminado           0.10.1\n",
       "tornado             6.1\n",
       "traitlets           5.0.5\n",
       "urllib3             1.26.6\n",
       "wcwidth             0.2.5\n",
       "websocket           0.57.0\n",
       "zmq                 22.1.0\n",
       "</pre>\n",
       "</details> <!-- seems like this ends pre, so might as well be explicit -->\n",
       "<pre>\n",
       "-----\n",
       "IPython             7.25.0\n",
       "jupyter_client      6.1.12\n",
       "jupyter_core        4.7.1\n",
       "jupyterlab          3.1.1\n",
       "notebook            6.4.0\n",
       "-----\n",
       "Python 3.8.10 (default, May 19 2021, 11:01:55) [Clang 10.0.0 ]\n",
       "macOS-10.16-x86_64-i386-64bit\n",
       "-----\n",
       "Session information updated at 2021-08-08 09:31\n",
       "</pre>\n",
       "</details>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "session_info.show(write_req_file=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incoming-symbol",
   "metadata": {},
   "source": [
    "## Make X and y data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "embedded-ukraine",
   "metadata": {},
   "outputs": [],
   "source": [
    "amount_of_features = 10\n",
    "amount_informative = 2\n",
    "X, y = make_classification(n_samples=300,\n",
    "    n_features=amount_of_features,\n",
    "    n_informative=amount_informative,\n",
    "#                              noise=5,\n",
    "#                              coef=True, \n",
    "                            random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "liable-turkish",
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X + 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "automatic-heath",
   "metadata": {},
   "source": [
    "## Fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "warming-rochester",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = (pd.DataFrame(X, columns=[f\"feat_{x}\" for x in range(0, X.shape[1])])\n",
    ".merge(pd.DataFrame(y, columns=[\"target\"]),\n",
    "      left_index=True,\n",
    "      right_index=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "interstate-focus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_0</th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.025</td>\n",
       "      <td>1.452</td>\n",
       "      <td>-1.203</td>\n",
       "      <td>1.248</td>\n",
       "      <td>-0.508</td>\n",
       "      <td>0.923</td>\n",
       "      <td>0.300</td>\n",
       "      <td>-0.453</td>\n",
       "      <td>-0.148</td>\n",
       "      <td>0.327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.750</td>\n",
       "      <td>0.098</td>\n",
       "      <td>0.664</td>\n",
       "      <td>-0.680</td>\n",
       "      <td>0.254</td>\n",
       "      <td>-0.339</td>\n",
       "      <td>-0.392</td>\n",
       "      <td>1.086</td>\n",
       "      <td>0.468</td>\n",
       "      <td>0.308</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.236</td>\n",
       "      <td>-0.839</td>\n",
       "      <td>-0.903</td>\n",
       "      <td>0.922</td>\n",
       "      <td>0.538</td>\n",
       "      <td>0.411</td>\n",
       "      <td>-1.966</td>\n",
       "      <td>-0.365</td>\n",
       "      <td>1.073</td>\n",
       "      <td>-1.045</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.615</td>\n",
       "      <td>-0.756</td>\n",
       "      <td>-0.722</td>\n",
       "      <td>0.729</td>\n",
       "      <td>-0.668</td>\n",
       "      <td>0.183</td>\n",
       "      <td>-0.898</td>\n",
       "      <td>-0.175</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.537</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.724</td>\n",
       "      <td>0.633</td>\n",
       "      <td>0.952</td>\n",
       "      <td>-0.997</td>\n",
       "      <td>-0.832</td>\n",
       "      <td>-0.903</td>\n",
       "      <td>-1.516</td>\n",
       "      <td>-0.552</td>\n",
       "      <td>0.471</td>\n",
       "      <td>0.203</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   feat_0  feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  \\\n",
       "0  -0.025   1.452  -1.203   1.248  -0.508   0.923   0.300  -0.453  -0.148   \n",
       "1   0.750   0.098   0.664  -0.680   0.254  -0.339  -0.392   1.086   0.468   \n",
       "2  -1.236  -0.839  -0.903   0.922   0.538   0.411  -1.966  -0.365   1.073   \n",
       "3  -1.615  -0.756  -0.722   0.729  -0.668   0.183  -0.898  -0.175   0.992   \n",
       "4  -0.724   0.633   0.952  -0.997  -0.832  -0.903  -1.516  -0.552   0.471   \n",
       "\n",
       "   feat_9  target  \n",
       "0   0.327       1  \n",
       "1   0.308       0  \n",
       "2  -1.045       1  \n",
       "3   0.537       1  \n",
       "4   0.203       0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "complimentary-bruce",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df.sample(frac=0.8, random_state=69420)\n",
    "df_test = df.drop(df_train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "identified-hazard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((240, 11), (60, 11))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.shape, df_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "welsh-narrative",
   "metadata": {},
   "source": [
    "## Fit the romeo LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "serious-alaska",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "CasADi - 2021-08-08 09:31:24 WARNING(\"ols:nlp_grad_f failed: NaN detected for output grad_f_x, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n",
      "CasADi - 2021-08-08 09:31:24 WARNING(\"ols:nlp_grad_f failed: NaN detected for output grad_f_x, at (row 0, col 0).\") [.../casadi/core/oracle_function.cpp:265]\n"
     ]
    }
   ],
   "source": [
    "reg = LogisticRegression(fit_intercept=True,\n",
    "                      normalize=True).fit(X=df_train.filter(regex=\"feat\"), \n",
    "                                               y=df_train[\"target\"], \n",
    "                                               verbose=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "southern-universe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.0, array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg.intercept_, reg.coef_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "naughty-northwest",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'LogisticRegression' object has no attribute 'summary_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/rc/1g_69mqs4t5dxcsd6dbczl_m0000gn/T/ipykernel_2990/3682259650.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;31m#reg.score(X, y)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'LogisticRegression' object has no attribute 'summary_'"
     ]
    }
   ],
   "source": [
    "reg.summary_.round(3)\n",
    "#reg.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "departmental-potential",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg.fit_evaluation_.round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "headed-webster",
   "metadata": {},
   "source": [
    "## Show the available methods and attributes of the fitted model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "single-wheel",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(dir(reg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "supposed-newfoundland",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reg.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adult-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.df_resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "protected-optimization",
   "metadata": {},
   "outputs": [],
   "source": [
    "intercept = reg.intercept_\n",
    "coefs = reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agricultural-playing",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "genuine-proceeding",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs.reshape(1,-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "brazilian-overall",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs*df_train.filter(regex=\"feat\").head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "finnish-socket",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_x = df_train.filter(regex=\"feat\").assign(intercept=1).set_index(\"intercept\").reset_index().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "executive-chick",
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_x = reg.intercept_ * tmp_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nasty-prince",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.linalg.inv(np.dot(tmp_x.T, tmp_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-class",
   "metadata": {},
   "outputs": [],
   "source": [
    "cov_mat = np.linalg.inv(np.matmul(tmp_x.transpose(1,0), tmp_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "forty-projector",
   "metadata": {},
   "outputs": [],
   "source": [
    "# abs(cov_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-white",
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sqrt(np.diag(abs(cov_mat)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "organized-store",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pd.DataFrame(np.cov(tmp_x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "reduced-broadcasting",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statsmodels cov_params\n",
    "\"\"\"\n",
    "Notes\n",
    "-----\n",
    "(The below are assumed to be in matrix notation.)\n",
    "If no argument is specified returns the covariance matrix of a model\n",
    "``(scale)*(X.T X)^(-1)``\n",
    "If contrast is specified it pre and post-multiplies as follows\n",
    "``(scale) * r_matrix (X.T X)^(-1) r_matrix.T``\n",
    "If contrast and other are specified returns\n",
    "``(scale) * r_matrix (X.T X)^(-1) other.T``\n",
    "If column is specified returns\n",
    "``(scale) * (X.T X)^(-1)[column,column]`` if column is 0d\n",
    "OR\n",
    "``(scale) * (X.T X)^(-1)[column][:,column]`` if column is 1d\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "amber-position",
   "metadata": {},
   "source": [
    "## Plot the original data and the lines of best fit for each of the predictors on the target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aquatic-stupid",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(12, 7))\n",
    "_ = plt.plot(df_train.filter(regex=\"feat\"), \n",
    "             df_train[\"target\"], \n",
    "             'o', \n",
    "             label='original data')\n",
    "_ = plt.plot(df_train.filter(regex=\"feat\"), \n",
    "             intercept + coefs*df_train.filter(regex=\"feat\"), \n",
    "             'r', \n",
    "             label='fitted line')\n",
    "# _ = plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-programming",
   "metadata": {},
   "source": [
    "## With the fitted model attempt to predict the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "electronic-worse",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = reg.predict(df_test.filter(regex=\"feat\"))\n",
    "y_pred.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accepted-license",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = df_test[[\"target\"]]\n",
    "y_test.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "magnetic-tobacco",
   "metadata": {},
   "source": [
    "## Calculate the Log loss between the predicted vs the real scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "signed-quick",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss_score = log_loss(y_test[\"target\"], \n",
    "        y_pred)\n",
    "log_loss_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "optional-contribution",
   "metadata": {},
   "source": [
    "## Plot the predicted vs the real values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wired-consistency",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_mat = confusion_matrix(y_test[\"target\"], y_pred.round(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continuing-imperial",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap='Blues'\n",
    "categories=[\"0\", \"1\"]\n",
    "\n",
    "_ = sns.heatmap(c_mat, \n",
    "                annot=True,            \n",
    "#                 fmt=\"\",\n",
    "                cmap=cmap,\n",
    "#                 cbar=cbar,\n",
    "                xticklabels=categories,\n",
    "                yticklabels=categories\n",
    "               )\n",
    "_ = plt.title(\"Confusion Matrix\")\n",
    "# _ = plt.xlabel(f'Predicted value\\n\\nAccuracy={summary_df[\"Accuracy\"].values[0]}\\nSensitivity={summary_df[\"Sensitivity\"].values[0]}\\nSpecificity={summary_df[\"Specificity\"].values[0]}\\nF1 Score={summary_df[\"F1\"].values[0]}')\n",
    "_ = plt.xlabel(f'Predicted value')\n",
    "_ = plt.ylabel(\"True value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-france",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = plt.figure(figsize=(12, 7))\n",
    "# _ = plt.plot(y_test[\"target\"], \n",
    "#              y_pred, \n",
    "#              'o', \n",
    "# #              label='original data'\n",
    "#             )\n",
    "# _ = plt.annotate(text = f\"Log Loss = {round(log_loss, 5)}\",\n",
    "#                  xy=(0.9, 0.1),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "posted-burton",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresh = roc_curve(y_true=y_test[\"target\"], y_score=y_pred, pos_label=1, sample_weight=None, drop_intermediate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "final-benefit",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score = roc_auc_score(y_true=y_test[\"target\"], y_score=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "alternate-program",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(12, 7))\n",
    "_ = plt.plot(fpr, \n",
    "             tpr, \n",
    "#              'o', \n",
    "            )\n",
    "_ = plt.plot(fpr, \n",
    "             tpr, \n",
    "             'o',\n",
    "             c=\"orange\"\n",
    "            )\n",
    "\n",
    "_ = plt.annotate(text = f\"AUC = {round(auc_score, 5)}\",\n",
    "                 xy=(0.9, 0.1),)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "appointed-mason",
   "metadata": {},
   "source": [
    "# Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unexpected-photograph",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels\n",
    "# from statsmodels.regression.linear_model import OLS\n",
    "from statsmodels.discrete.discrete_model import Logit\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "advised-crack",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train[\"target\"]\n",
    "# statsmodels.tools.tools.add_constant(data=df_train.filter(regex=\"feat\"), prepend=True, has_constant='skip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comfortable-iraqi",
   "metadata": {},
   "outputs": [],
   "source": [
    "res = Logit(endog=df_train[\"target\"], exog=statsmodels.tools.tools.add_constant(data=df_train.filter(regex=\"feat\"), prepend=True, has_constant='skip')).fit()\n",
    "# res = Logit(endog=df_train[\"target\"], exog=df_train.filter(regex=\"feat\"), prepend=True, has_constant='skip').fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tender-setup",
   "metadata": {},
   "outputs": [],
   "source": [
    "coefs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aboriginal-quantity",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "stone-money",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def bse(self):\n",
    "#         return np.sqrt(np.diag(self.cov_params()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "viral-partner",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.round(res.bse, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "better-quarterly",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.diag(res.cov_params()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "together-childhood",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.cov_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "compatible-success",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(dir(res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "immune-promise",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "focused-accounting",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.summary_.round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smaller-celtic",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = res.predict(exog=statsmodels.tools.tools.add_constant(data=df_test.filter(regex=\"feat\"), prepend=True, has_constant='skip'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stunning-thinking",
   "metadata": {},
   "source": [
    "## Plot the predicted vs the real values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "applied-fraction",
   "metadata": {},
   "outputs": [],
   "source": [
    "c_mat = confusion_matrix(y_test[\"target\"], y_pred.round(0),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "canadian-pepper",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmap='Blues'\n",
    "categories=[\"0\", \"1\"]\n",
    "\n",
    "_ = sns.heatmap(c_mat, \n",
    "                annot=True,            \n",
    "#                 fmt=\"\",\n",
    "                cmap=cmap,\n",
    "#                 cbar=cbar,\n",
    "                xticklabels=categories,\n",
    "                yticklabels=categories\n",
    "               )\n",
    "_ = plt.title(\"Confusion Matrix\")\n",
    "# _ = plt.xlabel(f'Predicted value\\n\\nAccuracy={summary_df[\"Accuracy\"].values[0]}\\nSensitivity={summary_df[\"Sensitivity\"].values[0]}\\nSpecificity={summary_df[\"Specificity\"].values[0]}\\nF1 Score={summary_df[\"F1\"].values[0]}')\n",
    "_ = plt.xlabel(f'Predicted value')\n",
    "_ = plt.ylabel(\"True value\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beneficial-princess",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_loss_score = log_loss(y_test[\"target\"], \n",
    "        y_pred)\n",
    "log_loss_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "impossible-beast",
   "metadata": {},
   "outputs": [],
   "source": [
    "# _ = plt.figure(figsize=(12, 7))\n",
    "# _ = plt.plot(y_test[\"target\"], \n",
    "#              y_pred, \n",
    "#              'o', \n",
    "# #              label='original data'\n",
    "#             )\n",
    "# _ = plt.annotate(text = f\"Log Loss = {round(log_loss, 5)}\",\n",
    "#                  xy=(0.9, 0.1),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "after-extreme",
   "metadata": {},
   "outputs": [],
   "source": [
    "fpr, tpr, thresh = roc_curve(y_true=y_test[\"target\"], y_score=y_pred, pos_label=1, sample_weight=None, drop_intermediate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sharp-design",
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_score = roc_auc_score(y_true=y_test[\"target\"], y_score=y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "general-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "_ = plt.figure(figsize=(12, 7))\n",
    "_ = plt.plot(fpr, \n",
    "             tpr, \n",
    "#              'o', \n",
    "            )\n",
    "_ = plt.plot(fpr, \n",
    "             tpr, \n",
    "             'o',\n",
    "             c=\"orange\"\n",
    "            )\n",
    "\n",
    "_ = plt.annotate(text = f\"AUC = {round(auc_score, 5)}\",\n",
    "                 xy=(0.9, 0.1),)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "hungry-racing",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.fit_evaluation_.round(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thorough-housing",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "needed-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.llf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "comparable-cookie",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.params / res.bse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "recent-hometown",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.tvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "constant-attribute",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "traditional-depth",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.df_resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unsigned-adams",
   "metadata": {},
   "outputs": [],
   "source": [
    "stats.t.sf(np.abs(res.tvalues), res.df_resid) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "public-ranking",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(res.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "desperate-tiger",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.conf_int()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "european-jesus",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.rsquared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-modern",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.ssr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pacific-generator",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.resid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "durable-peter",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg.resid"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pymer4_env",
   "language": "python",
   "name": "pymer4_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
